{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generatig Emojis with a Diffusion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I have developed a basic Diffusion Model and trained it on emojis to generate new ones from random noise.\n",
    "\n",
    "The things I covered:\n",
    "1. Intuition behind Diffusion Models\n",
    "2. Math - Forward process explained in detail, Backward process explained in detail and Derivation of the loss function\n",
    "3. Implementing the forward process\n",
    "4. Implementing the Diffusion Model (Unet architecture)\n",
    "5. Preparing the dataset\n",
    "6. Sampling an image (Backward process)\n",
    "7. Training loop\n",
    "8. Generating new images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuition behind Diffusion Models\n",
    "\n",
    "**Main idea** - *The essential idea is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Diffusion Process\n",
    "\n",
    "Applying Gaussian noise to the image from the dataset a lot of times until we are left with pure noise.\n",
    "\n",
    "$$x_0 \\rightarrow x_1 \\rightarrow ... \\rightarrow x_T $$\n",
    "\n",
    "The image converges to noise which follows the normal distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Diffusion Process\n",
    "\n",
    "Applying a de-noising step to random noise a lot of times until we get an image similar to something from our dataset.\n",
    "\n",
    "$$x_T=random\\_noise \\rightarrow x_{T-1}=model(x_T) \\rightarrow ... \\rightarrow x_0=model(x_1)\n",
    "\n",
    "The model learns to predict the noise of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation:\n",
    "- $x_t$ - Image at timestep $t\\in\\{0,...T\\}$\n",
    "- $q(x_t|x_{t-1})$ - One step of the forward process\n",
    "- $p(x_{t-1}|x_t)$ - One step of the reverse process\n",
    "- $\\mathcal{N}(output; mean, variance)$ - Normal distribution\n",
    "- $\\beta_t$ - a parameter changing with a schedule (linear or cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward process:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$q(x_t|x_{t-1}) = \\mathcal{N}(x_t, \\sqrt{1-\\beta_t}x_{t-1}, \\beta_tI)$\n",
    "\n",
    "$q(x_t|x_{t-1}) = \\sqrt{1-\\beta_t}x_{t-1} + \\sqrt{\\beta_t}\\epsilon; \\hspace{0.3cm} \\epsilon \\sim \\mathcal{N}(0, 1)$\n",
    "\n",
    "$\\alpha_t=1-\\beta_t; \\hspace{0.3cm} \\overline{\\alpha}_t=\\prod_{s=1}^{t}\\alpha_s$\n",
    "\n",
    "$q(x_t|x_{t-1}) = \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\epsilon$\n",
    "\n",
    "$q(x_t|x_{t-2}) = \\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_t\\alpha_{t-1}}\\epsilon$\n",
    "\n",
    "$...$\n",
    "\n",
    "$q(x_t|x_{0}) = \\sqrt{\\overline{\\alpha}_t}x_0 + \\sqrt{1-\\overline{\\alpha}_t}\\epsilon$\n",
    "\n",
    "$q(x_t|x_0) = \\mathcal{N}(x_t, \\sqrt{\\overline{\\alpha}_t}x_0, (1-\\overline{\\alpha}_t)I)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reverse Process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\sum_\\theta(x_t, t))$\n",
    "\n",
    "- $\\sum_\\theta(x_t, t)$ will just be a constant, not a learnable function\n",
    "\n",
    "**Loss function** - Negative log likelyhood: $-log(p_\\theta(x_0))$\n",
    "- We want to use the Negative log likelyhood as the loss function, but the probability of $x_0$ is not easy to compute since we would need all the previous steps to do so.\n",
    "- *Solution* - Variational Lower Bound\n",
    "$$- \\log(p_{\\theta}(x_0)) \\leq -\\log(p_{\\theta}(x_0)) + D_{KL}(q(x_{1:T} | x_0) \\| p_{\\theta}(x_{1:T} | x_0))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kullback-Leibler** (KL) divergence: $D_{KL}(P \\parallel Q) = \\int P(x) \\log\\left(\\frac{P(x)}{Q(x)}\\right) \\, dx = \\mathbb{E}_{x \\sim P(x)} \\left[ \\log \\left( \\frac{P(x)}{Q(x)} \\right) \\right]$. This is a measure of how similar two distributions are and the value is always non-negative.\n",
    "\n",
    "$$- \\log(p_{\\theta}(x_0)) \\leq - \\log p_{\\theta}(x_0) + \\mathbb{E}_{x_{1:T} \\sim q(x_{1:T} | x_0)} \\left[ \\log \\left( \\frac{q(x_{1:T} | x_0)}{p_{\\theta}(x_{1:T} | x_0)} \\right) \\right]$$\n",
    "\n",
    "Applying Bayes' rule to the $p_{\\theta}(x_{1:T} | x_0)$ term:\n",
    "\n",
    "$$p_{\\theta}(x_{1:T} | x_0) = \\frac{p_{\\theta}(x_0 | x_{1:T}) p_{\\theta}(x_{1:T})}{p_{\\theta}(x_0)} = \\frac{p_{\\theta}(x_0, x_{1:T})}{p_{\\theta}(x_0)} = \\frac{p_{\\theta}(x_{0:T})}{p_{\\theta}(x_0)}$$\n",
    "\n",
    "Taking the result back to the log:\n",
    "\n",
    "$$\\log \\left( \\frac{q(x_{1:T} | x_0)}{p_{\\theta}(x_{1:T} | x_0)} \\right) = \\log \\left( \\frac{q(x_{1:T} | x_0)}{\\frac{p_{\\theta}(x_0, x_{1:T})}{p_{\\theta}(x_0)}} \\right) = \\log \\left( \\frac{q(x_{1:T} | x_0)}{p_{\\theta}(x_{0:T})} \\right) + \\log(p_{\\theta}(x_0))$$\n",
    "\n",
    "Substituting the last result back into the inequality:\n",
    "\n",
    "$$- \\log(p{\\theta}(x_0)) \\leq \\mathbb{E}_{x_{1:T} \\sim q(x_{1:T} | x_0)} \\left[ \\log \\left( \\frac{q(x_{1:T} | x_0)}{p_{\\theta}(x_{0:T})} \\right) + \\log(p_{\\theta}(x_0)) \\right]$$\n",
    "\n",
    "Using the fact that $p_{\\theta}(x_{0:T})$ is independant of the expected value $\\mathbb{E}_{x_{1:T} \\sim q(x_{1:T} | x_0)}$:\n",
    "\n",
    "$$\\mathbb{E}_{x_{1:T} \\sim q(x_{1:T} | x_0)} \\left[ \\log \\left( \\frac{q(x_{1:T} | x_0)}{p_{\\theta}(x_{0:T})} \\right) + \\log(p_{\\theta}(x_0)) \\right] = \\mathbb{E}_{x_{1:T} \\sim q(x_{1:T} | x_0)} \\left[ \\log \\left( \\frac{q(x_{1:T} | x_0)}{p_{\\theta}(x_{0:T})} \\right) \\right] + \\log(p_{\\theta}(x_0))$$\n",
    "\n",
    "The two same terms of the inequality cancel out and we add the expected value to the left hand side since it doesn't affect its value:\n",
    "\n",
    "$$\\mathbb{E}_{x_{1:T} \\sim q(x_{1:T} | x_0)} [- \\log(p{\\theta}(x_0))] \\leq \\mathbb{E}_{x_{1:T} \\sim q(x_{1:T} | x_0)} \\left[ \\log \\left( \\frac{q(x{1:T} | x_0)}{p_{\\theta}(x_{0:T})} \\right) \\right]$$\n",
    "\n",
    "On the right-hand side, the denominator is the forwarding process starting from $x_0$, and the numerator is the reverse process:\n",
    "\n",
    "$$\\log \\left( \\frac{q(x_{1:T} | x_0)}{p_{\\theta}(x_{0:T})} \\right) = \\log \\left( \\frac{\\prod_{t=1}^{T} q(x_t | x_{t-1})}{p_{\\theta}(x_T) \\prod_{t=1}^{T} p_{\\theta}(x_{t-1} | x_t)} \\right) = - \\log p_{\\theta}(x_T) + \\sum_{t=1}^{T} \\log \\left( \\frac{q(x_t | x_{t-1})}{p_{\\theta}(x_{t-1} | x_t)} \\right)$$\n",
    "\n",
    "Now we will take the first element of the sum outside:\n",
    "\n",
    "$$- \\log p_{\\theta}(x_T) + \\sum_{t=1}^{T} \\log \\left( \\frac{q(x_t | x_{t-1})}{p_{\\theta}(x_{t-1} | x_t)} \\right) = - \\log p_{\\theta}(x_T) + \\sum_{t=2}^{T} \\log \\left( \\frac{q(x_t | x_{t-1})}{p_{\\theta}(x_{t-1} | x_t)} \\right) + \\log \\left( \\frac{q(x_1 | x_0)}{p_{\\theta}(x_0 | x_1)} \\right)$$\n",
    "\n",
    "Applying Bayers' rule to the numerator in the sum:\n",
    "\n",
    "$$q(x_t | x_{t-1}) = \\frac{q(x_{t-1} | x_t) q(x_t)}{q(x_{t-1})}$$\n",
    "\n",
    "The problem is that this has high variance, we solve that by conditioning on $x_0$ which does not affect the value of the expression due to the properties of Markov chains ($x_t$ is only dependant on $x_{t-1}$).\n",
    "\n",
    "$$\\frac{q(x_{t-1} | x_t) q(x_t)}{q(x_{t-1})} = \\frac{q(x_{t-1} | x_t, x_0) q(x_t | x_0)}{q(x_{t-1} | x_0)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this back in the original equation:\n",
    "\n",
    "$$- \\log p_{\\theta}(x_T) + \\sum_{t=2}^{T} \\log \\left( \\frac{q(x_t | x_{t-1})}{p_{\\theta}(x_{t-1} | x_t)} \\right) + \\log \\left( \\frac{q(x_1 | x_0)}{p_{\\theta}(x_0 | x_1)} \\right) = - \\log p_{\\theta}(x_T) + \\sum_{t=2}^{T} \\log \\left( \\frac{q(x_{t-1} | x_t, x_0) q(x_t | x_0)}{p_{\\theta}(x_{t-1} | x_t) q(x_{t-1} | x_0)} \\right) + \\log \\left( \\frac{q(x_1 | x_0)}{p_{\\theta}(x_0 | x_1)} \\right) $$\n",
    "\n",
    "Splitting the sum:\n",
    "\n",
    "$$\\sum_{t=2}^{T} \\log \\left( \\frac{q(x_{t-1} | x_t, x_0) q(x_t | x_0)}{p_{\\theta}(x_{t-1} | x_t) q(x_{t-1} | x_0)} \\right)\n",
    "=\n",
    "\\sum_{t=2}^{T} \\log \\left( \\frac{q(x_{t-1} | x_t, x_0)}{p_{\\theta}(x_{t-1} | x_t)} \\right) + \\sum_{t=2}^{T} \\log \\left( \\frac{q(x_t | x_0)}{q(x_{t-1} | x_0)} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the second summation from above, it simplifies down do this:\n",
    "\n",
    "$$\\frac{q(x_2 | x_0) q(x_3 | x_0) \\cdots q(x_{T-1} | x_0) q(x_T | x_0)}{q(x_1 | x_0) q(x_2 | x_0) \\cdots q(x_{T-2} | x_0) q(x_{T-1} | x_0)} = \\frac{q(x_T | x_0)}{q(x_1 | x_0)}$$\n",
    "\n",
    "Using this in the previous equation gets us:\n",
    "\n",
    "$$\\sum_{t=2}^{T} \\log \\left( \\frac{q(x_{t-1} | x_t, x_0) q(x_t | x_0)}{p_{\\theta}(x_{t-1} | x_t) q(x_{t-1} | x_0)} \\right)\n",
    "=\n",
    "\\sum_{t=2}^{T} \\log \\left( \\frac{q(x_{t-1} | x_t, x_0)}{p_{\\theta}(x_{t-1} | x_t)} \\right) + \\log \\left( \\frac{q(x_T | x_0)}{q(x_1 | x_0)} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituting this back:\n",
    "\n",
    "$$- \\log p_{\\theta}(x_T) + \\sum_{t=2}^{T} \\log \\left( \\frac{q(x_{t-1} | x_t, x_0) q(x_t | x_0)}{p_{\\theta}(x_{t-1} | x_t) q(x_{t-1} | x_0)} \\right) + \\log \\left( \\frac{q(x_1 | x_0)}{p_{\\theta}(x_0 | x_1)} \\right)$$\n",
    "$$= - \\log p_{\\theta}(x_T) + \\sum_{t=2}^{T} \\log \\left( \\frac{q(x_{t-1} | x_t, x_0)}{p_{\\theta}(x_{t-1} | x_t)} \\right) + \\log \\left( \\frac{q(x_T | x_0)}{q(x_1 | x_0)} \\right) + \\log \\left( \\frac{q(x_1 | x_0)}{p_{\\theta}(x_0 | x_1)} \\right)$$\n",
    "$$= - \\log p_{\\theta}(x_T) + \\sum_{t=2}^{T} \\log \\left( \\frac{q(x_{t-1} | x_t, x_0)}{p_{\\theta}(x_{t-1} | x_t)} \\right) + \\log \\left( \\frac{q(x_T | x_0) q(x_1 | x_0)}{q(x_1 | x_0) p_{\\theta}(x_0 | x_1)} \\right)$$\n",
    "$$= \\log q(x_T | x_0) - \\log p_{\\theta}(x_T) + \\sum_{t=2}^{T} \\log \\left( \\frac{q(x_{t-1} | x_t, x_0)}{p_{\\theta}(x_{t-1} | x_t)} \\right) - \\log p_{\\theta}(x_0 | x_1)$$\n",
    "$$= \\log \\left( \\frac{q(x_T | x_0)}{p_{\\theta}(x_T)} \\right) + \\sum_{t=2}^{T} \\log \\left( \\frac{q(x_{t-1} | x_t, x_0)}{p_{\\theta}(x_{t-1} | x_t)} \\right) - \\log p_{\\theta}(x_0 | x_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this back in the right hand side of the inequality for the lower bound. On the right side because we are calculating the expected value of the log ratios and by definition that is exactly the KL divergence of two distributions. We get this:\n",
    "\n",
    "$$\\mathbb{E}_{x_{1:T} \\sim q(x_{1:T} | x_0)} \\left[ \\log \\frac{q(x_{1:T} | x_0)}{p_{\\theta}(x_{0:T})} \\right] = \\underbrace{D_{KL}(q(x_T | x_0) \\parallel p_{\\theta}(x_T))}_{L_T} + \\sum_{t=2}^{T} \\underbrace{D_{KL}(q(x_{t-1} | x_t, x_0) \\parallel p_{\\theta}(x_{t-1} | x_t))}_{L_{t-1}} - \\underbrace{\\log p_{\\theta}(x_0 | x_1)}_{L_0}$$\n",
    "\n",
    "$L_T$ componenet can be ignored since q has no learnable parameters and $x_T$ is just Gaussian noise.\n",
    "\n",
    "We will take a look at the $L_t$ component. It calculates the KL divergence between $q$ and $p$. We already know the following:\n",
    "$p_{\\theta}(x_{t-1} | x_t) = \\mathcal{N}(x_{t-1}; \\mu_{\\theta}(x_t, t), \\sigma_t \\mathbf{I})$ (the variance is fixed). \n",
    "We can also write $q$ like this:\n",
    "$q(x_{t-1} | x_t, x_0) = \\mathcal{N}(x_{t-1}; \\tilde{\\mu}_{\\theta}(x_t, x_0), \\tilde{\\beta}_t \\mathbf{I})$\n",
    "\n",
    "Applying the Bayers' rule results in the following:\n",
    "$$q(x_{t-1} | x_t, x_0) = q(x_t | x_{t-1}, x_0) \\frac{q(x_{t-1} | x_0)}{q(x_t | x_0)}$$\n",
    "\n",
    "Let's remind ourselves of the general structure of a Gaussian distribution:\n",
    "\n",
    "$$ \\mathcal{N}(x) \\propto \\exp \\left( -\\frac{1}{2} \\frac{(x - \\mu)^2}{\\sigma^2} \\right) = \\exp \\left( -\\frac{1}{2} \\frac{x^2 - 2 \\mu x + \\mu^2}{\\sigma^2} \\right) = \\exp \\left( -\\frac{1}{2} \\left[ \\frac{1}{\\sigma^2}x^2 - \\frac{2 \\mu}{\\sigma^2}x + \\frac{\\mu^2}{\\sigma^2} \\right] \\right) $$\n",
    "\n",
    "All of the distributions from before are Gaussian, we will use this:\n",
    "- $ q(x_t | x_{t-1}, x_0) $: mean = $ \\sqrt{\\alpha_t} x_{t-1} $; variance = $ \\beta_t $\n",
    "- $ q(x_{t-1} | x_0) $: mean = $ \\sqrt{\\overline{\\alpha}_{t-1}} x_0 $; variance: $ \\sqrt{1-\\overline{\\alpha}_{t-1}} $\n",
    "- $ q(x_{t} | x_0) $: mean = $ \\sqrt{\\overline{\\alpha}_t} x_0 $; variance: $ \\sqrt{1-\\overline{\\alpha}_t} $\n",
    "\n",
    "Now we can combine their quadratic forms in the exponents and get this:\n",
    "\n",
    "$$q(x_{t-1} | x_t, x_0) \\propto \\exp \\left( -\\frac{1}{2} \\left[ \\frac{(x_t - \\sqrt{\\alpha_t} x_{t-1})^2}{\\beta_t} + \\frac{(x_{t-1} - \\sqrt{\\alpha_{t-1}} x_0)^2}{1 - \\tilde{\\alpha}_{t-1}} - \\frac{(x_t - \\sqrt{\\alpha_t} x_0)^2}{1 - \\tilde{\\alpha}_t} \\right] \\right)$$\n",
    "\n",
    "Rearranging the terms to get a Gaussian structure results in the following:\n",
    "\n",
    "$$ q(x_{t-1} | x_t, x_0) \\propto \\exp \\left( -\\frac{1}{2} \\left[ \\underbrace{\\left( \\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1 - \\bar{\\alpha}_{t-1}} \\right)}_{1/\\sigma^2} x_{t-1}^2 - \\underbrace{\\left( \\frac{2 \\sqrt{\\alpha_t}}{\\beta_t} x_t + \\frac{2 \\sqrt{\\bar{\\alpha}_{t-1}}}{1 - \\bar{\\alpha}_{t-1}} x_0 \\right)}_{2\\mu/\\sigma^2} x_{t-1} + \\underbrace{f(x_t, x_0)}_{\\mu^2/\\sigma^2} \\right] \\right) $$\n",
    "\n",
    "$f$ is some function of $x_t$ and $x_0$ which we do not need to find the mean and variance.\n",
    "\n",
    "From the first term, we get:\n",
    "\n",
    "$$ \\sigma^2 = \\tilde{\\beta}_t = \\frac{1}{\\left( \\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1 - \\bar{\\alpha}_{t-1}} \\right)} = \\frac{1}{\\left( \\frac{\\alpha_t - \\bar{\\alpha}_t + \\beta_t}{\\beta_t(1 - \\bar{\\alpha}_{t-1})} \\right)} = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\cdot \\beta_t $$\n",
    "\n",
    "From the second term and the result for variance we get:\n",
    "\n",
    "$$ \\tilde{\\mu}_t(x_t, x_0) = \\left( \\frac{\\sqrt{\\alpha_t}}{\\beta_t} x_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}}{1 - \\bar{\\alpha}_{t-1}} x_0 \\right) \\frac{1}{\\left( \\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1 - \\bar{\\alpha}_{t-1}} \\right)} \n",
    "= \\left( \\frac{\\sqrt{\\alpha_t}}{\\beta_t} x_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}}{1 - \\bar{\\alpha}_{t-1}} x_0 \\right) \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\cdot \\beta_t \n",
    "= \\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} x_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}} \\beta_t}{1 - \\bar{\\alpha}_t} x_0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the definitions in the beginning we can derive the following:\n",
    "\n",
    "$$ \\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon\n",
    "\\Rightarrow \\mathbf{x}_0 = \\frac{1}{\\sqrt{\\bar{\\alpha}_t}} \\left( \\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon \\right) $$\n",
    "\n",
    "Substituting this into the previous equation gives us:\n",
    "\n",
    "$$ \\tilde{\\mu}_t(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon \\right) $$\n",
    "\n",
    "If we look at the loss function we derived earlier, we see that $\\mu_\\theta$ should be trained to predict $\\tilde{\\mu_t}$. Since we already know $x_t$ in the reverse process, we only need to predict the noise at step $t$, that being $\\epsilon_t$. We can write $\\epsilon_t$ to be a function of $x_t$ and $t$, dependant on the trainable parameters of the neural network:\n",
    "\n",
    "$$ \\mu_{\\theta}(\\mathbf{x}_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_{\\theta}(\\mathbf{x}_t, t) \\right) $$\n",
    "\n",
    "Since we deal with Gaussians and the only parameter is the mean, using the KL divergence leads to the following loss:\n",
    "\n",
    "$$ L_t = \\frac{1}{2 \\sigma_t^2} \\left\\lVert \\tilde{\\mu}_t(\\mathbf{x}_t, \\mathbf{x}_0) - \\mu_{\\theta}(\\mathbf{x}_t, t) \\right\\rVert^2 $$\n",
    "$$ L_t = \\frac{1}{2 \\sigma_t^2} \\left\\lVert \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_t \\right) - \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_{\\theta}(\\mathbf{x}_t, t) \\right) \\right\\rVert^2 $$\n",
    "$$ L_t = \\frac{(1 - \\alpha_t)^2}{2 \\alpha_t (1 - \\bar{\\alpha}_t) \\sigma_t^2} \\left\\lVert \\epsilon_t - \\epsilon_{\\theta}(\\mathbf{x}_t, t) \\right\\rVert^2 $$\n",
    "\n",
    "In the [DDPM](https://arxiv.org/abs/2006.11239) paper, it is found empirically that the training works better if the scaling factor is omitted, therefore, we can simplify the loss to:\n",
    "\n",
    "$$ L_t = \\left\\lVert \\epsilon_t - \\epsilon_{\\theta}(\\mathbf{x}_t, t) \\right\\rVert^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have to handle the $L_0$ term in the loss function. The DDPM paper suggests using an independent discrete decoder derived from the Gaussian $ \\mathcal{N}(\\mathbf{x}_0; \\mu_{\\theta}(\\mathbf{x}_1, 1)\\sigma^2 \\mathbf{I}) $\n",
    "\n",
    "The paper also assumes that the image is originally constructed from discrete pixels with values {0, 1, 2, …, 255} that scaled to the range [-1, 1]. The distribution is then represented as:\n",
    "\n",
    "$$ p_{\\theta}(\\mathbf{x}_0 | \\mathbf{x}_1) = \\prod_{i=1}^{D} \\int_{\\delta_-(x_0^i)}^{\\delta_+(x_0^i)} \\mathcal{N}(x, \\mu_{\\theta}^i(\\mathbf{x}_1, 1), \\sigma_1^2) dx $$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\delta_+(x) =\n",
    "\\begin{cases}\n",
    "    \\infty & \\text{if } x = 1 \\\\\n",
    "    x + \\frac{1}{255} & \\text{if } x < 1\n",
    "\\end{cases}\n",
    "\\quad\n",
    "\\delta_-(x) =\n",
    "\\begin{cases}\n",
    "    -\\infty & \\text{if } x = -1 \\\\\n",
    "    x - \\frac{1}{255} & \\text{if } x > -1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "However, the paper simplifies this loss also. Instead of calculating the integral, it is approximated by the Gaussian probability density function times the bin width:\n",
    "\n",
    "$$ p_{\\theta}(\\mathbf{x}_0 | \\mathbf{x}_1) \\approx \\frac{1}{\\sqrt{2 \\pi \\sigma_1}} \\exp\\left( -\\frac{1}{2} \\frac{\\left\\lVert \\mathbf{x}_0 - \\mu_{\\theta}(\\mathbf{x}_1, 1) \\right\\rVert^2}{\\sigma_1^2} \\right) \\cdot \\frac{2}{255} $$\n",
    "\n",
    "and the log will be:\n",
    "\n",
    "$$ L_0 = - \\log(p_{\\theta}(\\mathbf{x}_0 | \\mathbf{x}_1)) \\approx \\frac{1}{2 \\sigma_1^2} \\left\\lVert \\mathbf{x}_0 - \\mu_{\\theta}(\\mathbf{x}_1, 1) \\right\\rVert^2 + C $$\n",
    "\n",
    "$C$ is a constant we can ignore for the loss function since it is not trainable.\n",
    "\n",
    "The same formula from before holds for $\\mu_{\\theta}(\\mathbf{x}_1, 1)$:\n",
    "\n",
    "$$ \\mu_{\\theta}(\\mathbf{x}_1, 1) = \\frac{1}{\\sqrt{\\alpha_1}} \\left( \\mathbf{x}_1 - \\frac{1 - \\alpha_1}{\\sqrt{1 - \\bar{\\alpha}_1}} \\epsilon_{\\theta}(\\mathbf{x}_1, 1) \\right) $$\n",
    "\n",
    "Substituting this in for $L_0$ and ignoring the scaling factors:\n",
    "\n",
    "$$ L_0 \\approx \\left\\lVert \\epsilon_1 - \\epsilon_{\\theta}(\\mathbf{x}_1, 1) \\right\\rVert^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified Training Objective\n",
    "\n",
    "The loss that will be used:\n",
    "\n",
    "$$ L_{\\text{simple}} := \\mathbb{E}_{t \\sim U[1, T], \\mathbf{x}_0, \\epsilon} \\left[ \\left\\lVert \\epsilon - \\epsilon_{\\theta}(\\mathbf{x}_t, t) \\right\\rVert^2 \\right] $$\n",
    "$$ L_{\\text{simple}} = \\mathbb{E}_{t \\sim U[1, T], \\mathbf{x}_0, \\epsilon} \\left[ \\left\\lVert \\epsilon - \\epsilon_{\\theta} \\left( \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, t \\right) \\right\\rVert^2 \\right] $$\n",
    "\n",
    "Training process:\n",
    "1. **Repeat**\n",
    "2. $\\mathbf{x}_0 \\sim q(\\mathbf{x}_0)$\n",
    "3. $t \\sim \\text{Uniform}(\\{1, \\dots, T\\})$\n",
    "4. $\\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$\n",
    "5. Take gradient descent step on: $ \\nabla_{\\theta} \\left\\lVert \\epsilon - \\epsilon_{\\theta} \\left( \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, t \\right) \\right\\rVert^2 $\n",
    "6. **Until** converged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for implenenting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Forward Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Schedule\n",
    "\n",
    "1. Linear schedule - This was used in the initial paper about denoising diffusion probabilistic models.\n",
    "2. Cosine schedule - This was later used in a subsequent paper ([*Improved Denoising Diffusion Probabilistic Models*](https://arxiv.org/abs/2102.09672)) and it has been shown to produce better results because information is lost more slowly than with the linear schedule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_schedule(num_timesteps):\n",
    "  beta_start = 1e-4\n",
    "  beta_end = 0.02\n",
    "  betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "  return betas\n",
    "\n",
    "def cosine_schedule(num_timesteps, s=0.008):\n",
    "  def f(t):\n",
    "    return torch.cos((t / num_timesteps + s) / (1 + s) * 0.5 * torch.pi) ** 2\n",
    "  x = torch.linspace(0, num_timesteps, num_timesteps + 1)\n",
    "  alphas_cumprod = f(x) / f(torch.tensor([0]))\n",
    "  betas = 1 - alphas_cumprod[1:] / alphas_cumprod[:-1]\n",
    "  betas = torch.clip(betas, 0.0001, 0.999)\n",
    "  return betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to define a function for sampling from the forward process. First, let’s define a helper function to sample a tensor sorted by time, according to timesteps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_by_t(tensor_to_sample, timesteps, x_shape):\n",
    "  batch_size = timesteps.shape[0]\n",
    "  sampled_tensor = tensor_to_sample.gather(-1, timesteps.cpu())\n",
    "  sampled_tensor = torch.reshape(sampled_tensor, (batch_size,) + (1,) * (len(x_shape) - 1))\n",
    "  return sampled_tensor.to(timesteps.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define αₜ, α̅ₜ, βₜ and some operation on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 500\n",
    "betas_t = linear_schedule(num_timesteps)\n",
    "\n",
    "alphas_t = 1. - betas_t\n",
    "alphas_bar_t = torch.cumprod(alphas_t, dim=0)\n",
    "alphas_bar_t_minus_1 = torch.cat((torch.tensor([0]), alphas_bar_t[:-1]))\n",
    "one_over_sqrt_alphas_t = 1. / torch.sqrt(alphas_t)\n",
    "sqrt_alphas_bar_t = torch.sqrt(alphas_bar_t)\n",
    "sqrt_1_minus_alphas_bar_t = torch.sqrt(1. - alphas_bar_t)\n",
    "\n",
    "# the variance of q(xₜ₋₁ | xₜ, x₀)\n",
    "posterior_variance = (1. - alphas_bar_t_minus_1) / (1. - alphas_bar_t) * betas_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward process sampling function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_q(x0, t, noise=None):\n",
    "  if noise is None:\n",
    "    noise = torch.randn_like(x0)\n",
    "\n",
    "  t = t.long()\n",
    "\n",
    "  sqrt_alphas_bar_t_sampled = sample_by_t(sqrt_alphas_bar_t, t, x0.shape)\n",
    "  sqrt_1_minus_alphas_bar_t_sampled = sample_by_t(sqrt_1_minus_alphas_bar_t, t, x0.shape)\n",
    "\n",
    "  xt = sqrt_alphas_bar_t_sampled * x0 + sqrt_1_minus_alphas_bar_t_sampled * noise\n",
    "\n",
    "  # clipping the values in range [-1, 1]\n",
    "  xt = torch.clamp(xt, -1, 1)\n",
    "  return xt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a random image from the interenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "url = 'https://images.pexels.com/photos/1557208/pexels-photo-1557208.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=2'\n",
    "image_raw_data = requests.get(url, stream=True).raw\n",
    "image = Image.open(image_raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the image into a torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, CenterCrop, Resize, Normalize, RandomHorizontalFlip\n",
    "\n",
    "image_size = 32\n",
    "transform = Compose([\n",
    "  Resize(image_size),  # resize smaller edge to image_size\n",
    "  CenterCrop(image_size),  # make a square image with size image_size\n",
    "  RandomHorizontalFlip(), # flip the image horizontally with a probability of 0.5\n",
    "  ToTensor(),  # convert to tensor with shape CHW and values in the range [0, 1]\n",
    "  Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) # set the values to the range [-1, 1]\n",
    "])\n",
    "\n",
    "x0 = transform(image).unsqueeze(0)\n",
    "print(x0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse transformation to return the image into a PIL object and one for getting a tensor with values in the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "reverse_transform_pil = Compose([\n",
    "  Normalize(mean=(-1, -1, -1), std=(2, 2, 2)),\n",
    "  ToPILImage()\n",
    "])\n",
    "\n",
    "reverse_transform_tensor = Compose([\n",
    "  Normalize(mean=(-1, -1, -1), std=(2, 2, 2)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that, given an image as a tensor and a timestep t, returns a noisy image sampled from the q distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_image(x0, t, transform=reverse_transform_pil):\n",
    "  x_noisy = sample_q(x0, t)\n",
    "  noise_image = transform(x_noisy.squeeze())\n",
    "  return noise_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for displaying the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_noisy_images(noisy_images):\n",
    "    \"\"\"\n",
    "    Show and return a grid of noisy images where\n",
    "    the rows are different images, and the columns\n",
    "    are the noisy images in different timesteps.\n",
    "\n",
    "    Args:\n",
    "    noisy_images (list[list[PIL]]): a list with a lists of images\n",
    "        with noise from different timesteps.\n",
    "    \"\"\"\n",
    "    num_of_image_sets = len(noisy_images)\n",
    "    num_of_images_in_set = len(noisy_images[0])\n",
    "    image_size = noisy_images[0][0].size[0]\n",
    "\n",
    "    full_image = Image.new('RGB', (image_size * num_of_images_in_set + (num_of_images_in_set - 1), image_size * num_of_image_sets + (num_of_image_sets - 1)))\n",
    "    for set_index, image_set in enumerate(noisy_images):\n",
    "        for image_index, image in enumerate(image_set):\n",
    "            full_image.paste(image, (image_index * image_size + image_index, set_index * image_size + set_index))\n",
    "    \n",
    "    plt.imshow(full_image)\n",
    "    plt.axis('off')\n",
    "    return full_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See an exaple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x0.shape)\n",
    "show_noisy_images([[get_noisy_image(x0, torch.tensor([t])) for t in [0, 100, 200, 300, 400, 499]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Diffusion Model (Unet architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Unet architecture\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W-RkwGIiKDF3A3WXwZQMWg.png\" alt=\"drawing\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture of the U-net\n",
    "\n",
    "Input: (32, 32, 3)\n",
    "\n",
    "Encoder:\n",
    "- Conv (3x3, filters=64), BatchNorm, ReLU\n",
    "- MaxPool (2x2)\n",
    "- Conv (3x3, filters=128), BatchNorm, ReLU\n",
    "- MaxPool (2x2)\n",
    "\n",
    "Bottleneck:\n",
    "- Conv (3x3, filters=256), BatchNorm, ReLU\n",
    "\n",
    "Decoder:\n",
    "- UpConv (transpose conv) or Bilinear Upsampling\n",
    "- Conv (3x3, filters=128), BatchNorm, ReLU\n",
    "- UpConv (transpose conv) or Bilinear Upsampling\n",
    "- Conv (3x3, filters=64), BatchNorm, ReLU\n",
    "\n",
    "Output:\n",
    "- Conv (1x1, filters=3), Sigmoid (for pixel values in [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetModel, self).__init__()\n",
    "\n",
    "        # Time embedding layers\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        # down layers - encoder\n",
    "        self.encoderConv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoderConv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # bottleneck layer\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # up layers - decoder (with residual connections)\n",
    "        self.upConv1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2, padding=0)\n",
    "        self.decoderConv1 = nn.Sequential(\n",
    "            nn.Conv2d(128*2, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.upConv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2, padding=0)\n",
    "        self.decoderConv2 = nn.Sequential(\n",
    "            nn.Conv2d(64*2, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # output layer generates the predicted noise (added a residual connection to the output, therefore adding three input channels)\n",
    "        self.output = nn.Conv2d(64+3, 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        # Embed time\n",
    "        time = time.float()\n",
    "        t_embed = self.time_mlp(time.unsqueeze(-1))\n",
    "\n",
    "        # encoder\n",
    "        x_down1 = self.encoderConv1(x)  # 3x32x32 -> 64x32x32\n",
    "        x_down2 = self.encoderConv2(self.pool(x_down1))  # 64x16x16 -> 128x16x16\n",
    "\n",
    "        # bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool(x_down2))  # 128x8x8 -> 256x8x8\n",
    "\n",
    "        # Add time embedding to bottleneck features\n",
    "        # bottleneck = bottleneck + t_embed.view(t_embed.size(0), -1, 1, 1)\n",
    "\n",
    "        # decoder\n",
    "        x_up1 = self.upConv1(bottleneck)\n",
    "        x_concat1 = torch.cat((x_up1, x_down2), dim=1)\n",
    "        x_upResult1 = self.decoderConv1(x_concat1)\n",
    "        x_up2 = self.upConv2(x_upResult1)\n",
    "        x_concat2 = torch.cat((x_up2, x_down1), dim=1)\n",
    "        x_upResult2 = self.decoderConv2(x_concat2)\n",
    "\n",
    "        # output\n",
    "        x_concat3 = torch.cat((x_upResult2, x), dim=1)\n",
    "        output = self.output(x_concat3)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to load the dataset consisted of the face-like emojis from the Apple folder in the [Full Emoji Dataset](https://www.kaggle.com/datasets/subinium/emojiimage-dataset). We do not need any labels for the images, since we are training a simple diffusion model without any additional conditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.image_filenames = os.listdir(image_folder)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.image_filenames[idx])\n",
    "        \n",
    "        # Open the image with RGBA mode\n",
    "        image = Image.open(img_path).convert('RGBA')\n",
    "\n",
    "        # Create a black background image of the same size\n",
    "        black_background = Image.new(\"RGBA\", image.size, (0, 0, 0, 255))\n",
    "\n",
    "        # Composite the original image on top of the black background\n",
    "        composite_image = Image.alpha_composite(black_background, image)\n",
    "\n",
    "        # Convert back to RGB, discarding the alpha channel\n",
    "        image = composite_image.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "# Usage example\n",
    "image_folder = './Dataset/image/Apple_Faces'\n",
    "dataset = ImageDataset(image_folder, transform=transform)\n",
    "\n",
    "# Load the first image\n",
    "first_image = dataset[0].unsqueeze(0)\n",
    "first_image = first_image.to(device)\n",
    "print(first_image.shape)\n",
    "\n",
    "# print((first_image+1)/2)\n",
    "# show_noisy_images([[get_noisy_image(first_image, torch.tensor([t])) for t in [0]]])\n",
    "show_noisy_images([[get_noisy_image(first_image, torch.tensor([t], device=device)) for t in [0, 100, 200, 300, 400, 499]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function which shows the image from a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_image(image_tensor):\n",
    "    image_tensor = image_tensor.permute(1, 2, 0)\n",
    "\n",
    "    # Convert the tensor to a numpy array (bring channels to last dimension)\n",
    "    image_np = image_tensor.numpy()\n",
    "    \n",
    "    # Clip the values to be between 0 and 1 for proper visualization\n",
    "    image_np = (image_np + 1) / 2\n",
    "    \n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_tensor_image(first_image[0].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling an image (Backward process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling an image is done step by step by removing noise from the initial randomly generated image (x_T). To achieve that, an image is sampled from the distributions $q(x_{t-1}|x_t)$ repeatedly for $t \\in [1,...T]$, until $x_0$ is generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mu_t(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right) = \\frac{\\sqrt{\\bar{\\alpha}_{t-1} \\beta_t}}{1 - \\bar{\\alpha}_t} \\mathbf{x}_0 + \\frac{\\sqrt{\\alpha_t (1 - \\bar{\\alpha}_{t-1})}}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t$$\n",
    "\n",
    "$$ \\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right) + \\sigma_t \\mathbf{z} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following program implements the backward noise removal step in the image generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_p(model, x_t, t, clipping=True):\n",
    "  \"\"\"\n",
    "  Sample from p_θ(xₜ₋₁|xₜ) to get xₜ₋₁ according to the algorithm (as seen below)\n",
    "  \"\"\"\n",
    "  # putting x_t to the same device as the model\n",
    "  x_t = x_t.to(next(model.parameters()).device)\n",
    "\n",
    "  t = t.long()\n",
    "  betas_t_sampled = sample_by_t(betas_t, t, x_t.shape)\n",
    "  sqrt_1_minus_alphas_bar_t_sampled = sample_by_t(sqrt_1_minus_alphas_bar_t, t, x_t.shape)\n",
    "  one_over_sqrt_alphas_t_sampled = sample_by_t(one_over_sqrt_alphas_t, t, x_t.shape)\n",
    "\n",
    "  if clipping:\n",
    "    sqrt_alphas_bar_t_sampled = sample_by_t(sqrt_alphas_bar_t, t, x_t.shape)\n",
    "    sqrt_alphas_bar_t_minus_1_sampled = sample_by_t(torch.sqrt(alphas_bar_t_minus_1), t, x_t.shape)\n",
    "    alphas_bar_t_sampled = sample_by_t(alphas_bar_t, t, x_t.shape)\n",
    "    sqrt_alphas_t_sampled = sample_by_t(torch.sqrt(alphas_t), t, x_t.shape)\n",
    "    alphas_bar_t_minus_1_sampled = sample_by_t(alphas_bar_t_minus_1, t, x_t.shape)\n",
    "\n",
    "    x0_reconstruct = 1 / sqrt_alphas_bar_t_sampled * (x_t - sqrt_1_minus_alphas_bar_t_sampled * model(x_t, t/num_timesteps))\n",
    "    x0_reconstruct = torch.clamp(x0_reconstruct, -1., 1.)\n",
    "    predicted_mean = (sqrt_alphas_bar_t_minus_1_sampled * betas_t_sampled) / (1 - alphas_bar_t_sampled) * x0_reconstruct + (sqrt_alphas_t_sampled * (1 - alphas_bar_t_minus_1_sampled)) /  (1 - alphas_bar_t_sampled) * x_t\n",
    "\n",
    "  else:\n",
    "    predicted_mean = one_over_sqrt_alphas_t_sampled * (x_t - betas_t_sampled / sqrt_1_minus_alphas_bar_t_sampled * model(x_t, t/num_timesteps))\n",
    "\n",
    "  if t[0].item() == 1:\n",
    "    return predicted_mean\n",
    "  else:\n",
    "    posterior_variance_sampled = sample_by_t(posterior_variance, t, x_t.shape)\n",
    "    noise = torch.randn_like(x_t)\n",
    "    result = predicted_mean + torch.sqrt(posterior_variance_sampled) * noise\n",
    "    result = torch.clamp(result, -1., 1.)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full algorithm for sampling images is the following:\n",
    "1. $\\mathbf{x}_T \\sim \\mathcal{N}(0, \\mathbf{I})$\n",
    "2. **for** $t = T, \\dots, 1 \\text{ do}$\n",
    "3. $\\mathbf{z} \\sim \\mathcal{N}(0, \\mathbf{I}) \\text{ if } t > 1, \\text{ else } \\mathbf{z} = 0$\n",
    "4. $\\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right) + \\sigma_t \\mathbf{z}$\n",
    "5. **end for**\n",
    "6. return $x_0$\n",
    "\n",
    "Step 4. was implemented in the $sample\\_p$ function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full sampling algorithm implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "@torch.no_grad()\n",
    "def sampling(model, shape, image_noise_steps_to_keep=1):\n",
    "  \"\"\"\n",
    "  Implmenting Algorithm 2 - sampling.\n",
    "  Args:\n",
    "    model (torch.Module): the model that predictד the noise\n",
    "    shape (tuple): shape of the data (batch, channels, image_size, image_size)\n",
    "  Returns:\n",
    "    (list): list containing the images in the different steps of the reverse process\n",
    "  \"\"\"\n",
    "\n",
    "  batch = shape[0]\n",
    "  images = torch.randn(shape, device=device)  # pure noise\n",
    "  images_list = []\n",
    "\n",
    "  # for timestep in tqdm(range(num_timesteps-1, 0, -1), desc='sampling timestep'):\n",
    "  for timestep in range(num_timesteps-1, 0, -1):\n",
    "    images = sample_p(model, images, torch.full((batch,), timestep, dtype=torch.long).to(device))\n",
    "    if timestep <= image_noise_steps_to_keep or True:\n",
    "      images_list.append(images.cpu())\n",
    "  return images_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model, loss function, optimizer and dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetModel().to(device)\n",
    "\n",
    "def compute_loss(model, x0, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x0).to(device)\n",
    "\n",
    "    x_t = sample_q(x0, t.int(), noise)\n",
    "    predicted_noise = model(x_t, t/num_timesteps)\n",
    "    loss = F.mse_loss(noise, predicted_noise)\n",
    "    return loss\n",
    "    \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small tests before tranining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling an image before traning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = sampling(model.to(device), first_image.shape)\n",
    "print(len(test_result))\n",
    "show_tensor_image(test_result[-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a test to see the noise prediction of the model before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "with torch.no_grad():\n",
    "    test_output = model(sample_q(first_image.to(device), torch.tensor([100], device=device)), torch.tensor([100./num_timesteps]).to(device))\n",
    "    print(test_output.shape)\n",
    "    show_tensor_image(test_output[0].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop:\n",
    "\n",
    "Training process (from the 'math' part):\n",
    "1. **Repeat**\n",
    "2. $\\mathbf{x}_0 \\sim q(\\mathbf{x}_0)$\n",
    "3. $t \\sim \\text{Uniform}(\\{1, \\dots, T\\})$\n",
    "4. $\\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$\n",
    "5. Take gradient descent step on: $ \\nabla_{\\theta} \\left\\lVert \\epsilon - \\epsilon_{\\theta} \\left( \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, t \\right) \\right\\rVert^2 $\n",
    "6. **Until** converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "start_epoch = 0\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "  for batch_index, batch in enumerate(dataloader):\n",
    "    images = batch.to(device)\n",
    "    # sample t according to Algorithm 1\n",
    "    t = torch.randint(1, num_timesteps, (images.shape[0],), device=device).float()\n",
    "    loss = compute_loss(model, images, t)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  if epoch % 50 == 0: print(f\"Epoch: {epoch}, loss={loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a few emojis with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    test_result = sampling(model, first_image.shape)\n",
    "\n",
    "    # get max and min value in the tensor\n",
    "    max = torch.max(test_result[-1])\n",
    "    min = torch.min(test_result[-1])\n",
    "\n",
    "    # scaling the color values range from [min, max] to [-1, 1] linearly\n",
    "    scaled_image = (test_result[-1] - min) / (max - min) * 2 - 1\n",
    "\n",
    "\n",
    "    show_tensor_image(scaled_image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Probabilistic Denoising Diffusion Models are a lot more complex than Autoregressive models, but I would say that it results in better images. This model was able to better learn the patterns and produces results that are more realistic. The only downside I have noticed is its inconcistency with the colors.\n",
    "\n",
    "Colors are always a little bit off and not as saturated, but the patterns and faces the model generates are extremely good for something that needed just around one minute of training.\n",
    "\n",
    "When it comest to performance, training took similarly long as the autoregression model, but sampling is a lot faster with a diffusion model, around 3 seconds per image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
